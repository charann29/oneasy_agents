<!DOCTYPE html>
<html>

<head>
    <title>Voice Test</title>
</head>

<body>
    <h1>Voice Transcription Test</h1>
    <button id="startBtn">Start Recording</button>
    <button id="stopBtn" disabled>Stop Recording</button>
    <div id="status"></div>
    <div id="transcript"></div>

    <script>
        let mediaRecorder;
        let audioChunks = [];
        const statusDiv = document.getElementById('status');
        const transcriptDiv = document.getElementById('transcript');
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');

        startBtn.addEventListener('click', async () => {
            try {
                statusDiv.textContent = 'Requesting microphone access...';

                const stream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        channelCount: 1,
                        sampleRate: 16000,
                        echoCancellation: true,
                        noiseSuppression: true,
                    }
                });

                statusDiv.textContent = 'Microphone access granted. Recording...';

                mediaRecorder = new MediaRecorder(stream, {
                    mimeType: 'audio/webm',
                });

                audioChunks = [];

                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                        statusDiv.textContent = `Recording... ${event.data.size} bytes captured`;
                    }
                };

                mediaRecorder.onstop = async () => {
                    statusDiv.textContent = 'Processing audio...';
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    console.log('Audio blob size:', audioBlob.size);

                    const formData = new FormData();
                    formData.append('audio', audioBlob, 'test.webm');
                    formData.append('language', 'en-US');

                    try {
                        statusDiv.textContent = 'Sending to server...';
                        const response = await fetch('/api/voice/transcribe', {
                            method: 'POST',
                            body: formData,
                        });

                        statusDiv.textContent = 'Received response...';
                        const data = await response.json();

                        if (data.transcription) {
                            transcriptDiv.innerHTML = '<strong>Transcription:</strong> ' + data.transcription;
                            statusDiv.textContent = 'Success!';
                        } else {
                            transcriptDiv.textContent = 'Error: ' + (data.error || 'No transcription');
                            statusDiv.textContent = 'Failed';
                        }

                        console.log('Response:', data);
                    } catch (err) {
                        statusDiv.textContent = 'Network error: ' + err.message;
                        console.error('Fetch error:', err);
                    }

                    stream.getTracks().forEach(track => track.stop());
                };

                mediaRecorder.start();
                startBtn.disabled = true;
                stopBtn.disabled = false;

            } catch (err) {
                statusDiv.textContent = 'Error: ' + err.message;
                console.error('Error:', err);
            }
        });

        stopBtn.addEventListener('click', () => {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
                startBtn.disabled = false;
                stopBtn.disabled = true;
            }
        });
    </script>
</body>

</html>